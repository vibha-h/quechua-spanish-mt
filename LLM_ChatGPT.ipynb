{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d6b16e-0362-48f5-8d4d-654b477042d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install openai datasets\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from time import sleep\n",
    "from datasets import load_dataset\n",
    "from functools import partial\n",
    "\n",
    "IMDB_DATASET = load_dataset(\"imdb\", split='train').shuffle(42)[0:200]\n",
    "IMDB_DATASET_X = IMDB_DATASET['text']\n",
    "IMDB_DATASET_Y = IMDB_DATASET['label']\n",
    "del IMDB_DATASET\n",
    "\n",
    "\n",
    "## TODO - Start\n",
    "OPENAI_API_KEY = \"\"\n",
    "\n",
    "cache = {}\n",
    "def run_gpt3(prompt, return_first_line = True, instruction_tuned = False):\n",
    "    # Return the response from the cache if we have already run this\n",
    "    cache_key = (prompt, return_first_line, instruction_tuned)\n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    client = OpenAI(\n",
    "      api_key=OPENAI_API_KEY,\n",
    "    )\n",
    "    # Set the API Key\n",
    "\n",
    "\n",
    "    # Select the model\n",
    "    if instruction_tuned:\n",
    "        model = \"gpt-3.5-turbo-instruct\"\n",
    "    else:\n",
    "        model = \"davinci-002\"\n",
    "\n",
    "    # Send the prompt to GPT-3\n",
    "    for i in range(0,60,6):\n",
    "        try:\n",
    "            response = client.completions.create(\n",
    "                model=model,\n",
    "                prompt=prompt,\n",
    "                temperature=0,\n",
    "                max_tokens=100,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0.0,\n",
    "                presence_penalty=0.0,\n",
    "            )\n",
    "            response = dict(response)['choices'][0]\n",
    "            response = dict(response)['text'].strip()\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            sleep(i)\n",
    "\n",
    "    # Parse the response\n",
    "    if return_first_line:\n",
    "        final_response = response.split('.')[0]+'.'\n",
    "        if '\\n' in final_response:\n",
    "          final_response = response.split('\\n')[0]\n",
    "    else:\n",
    "        final_response = response\n",
    "\n",
    "    # Cache and return the response\n",
    "    cache[cache_key] = final_response\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1c47b4-09c4-4a00-8f28-e3addf139cde",
   "metadata": {},
   "source": [
    "## Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b021d682-e755-49a8-8f07-20bcf827f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase 1:\n",
      "ChatGPT response:\n",
      "Yo estoy comiendo carne.\n",
      "Actual Translation:\n",
      "yo como carne\n",
      "\n",
      "\n",
      "Phrase 2:\n",
      "ChatGPT response:\n",
      "¿Qué piensas?.\n",
      "Actual Translation:\n",
      "¿quien eres?\n",
      "\n",
      "\n",
      "Phrase 3:\n",
      "ChatGPT response:\n",
      "El conocimiento es una herramienta poderosa que nos permite comprender el mundo que nos rodea y tomar decisiones informadas.\n",
      "Actual Translation:\n",
      "En nuestra casa de estudios\n",
      "\n",
      "\n",
      "Phrase 4:\n",
      "ChatGPT response:\n",
      "A través de la enseñanza y el aprendizaje en la escuela, podemos expandir nuestro conocimiento.\n",
      "Actual Translation:\n",
      "El profesor y sus alumnos están en el aula.\n",
      "\n",
      "\n",
      "Phrase 5:\n",
      "ChatGPT response:\n",
      "¿Entiendes todo lo que te he enseñado?.\n",
      "Actual Translation:\n",
      "Estamos bien, mi profesor. ¿Y tú?\n",
      "\n",
      "\n",
      "Phrase 6:\n",
      "ChatGPT response:\n",
      "Yo creo en San Isidro.\n",
      "Actual Translation:\n",
      " Yo, por mi parte, vivo en San Isidro.\n",
      "\n",
      "\n",
      "Phrase 7:\n",
      "ChatGPT response:\n",
      "¿Puedo preguntarte algo, mamá, por favor, Ricardo?.\n",
      "Actual Translation:\n",
      "Yo suelo cocinar para mi mamá, ¿y tú, oye, Ricardo?\n",
      "\n",
      "\n",
      "Phrase 8:\n",
      "ChatGPT response:\n",
      "Sí, yo también juego al fútbol.\n",
      "Actual Translation:\n",
      "Sí, yo suelo jugar fútbol.\n",
      "\n",
      "\n",
      "Phrase 9:\n",
      "ChatGPT response:\n",
      "¿Qué significa eso en tu idioma?.\n",
      "Actual Translation:\n",
      "¿Cuándo vas a terminar la revista?\n",
      "\n",
      "\n",
      "Phrase 10:\n",
      "ChatGPT response:\n",
      "¿Qué significa eso?.\n",
      "Actual Translation:\n",
      "¿Cómo está?\n"
     ]
    }
   ],
   "source": [
    "QUECHUA_TO_SPANISH_PROMPT = \"Chaymantam mana musyaylla hatun kallpata wikutimun kay Allpa pachanchikpa muyuriqninman karullay - karukama. : El núcleo externo de la Tierra, que se compone mayormente de hierro fundido, genera un poderoso campo electromagnético que se eleva hacia el espacio y nos envuelve.\\n Chay punchawllapitaqmi achka waranqa runakunatapas Jehova Diosqa akllaykurqa, ichaqa manam bibliapi ninchu paykunapa umanpipas nina lenguachkaq hina kasqanmantaqa. : Por ejemplo, aquel mismo día Dios ungió a varios miles de personas más, pero la Biblia no dice que también tuvieran llamas sobre la cabeza.\\n{input} : \"\n",
    "\n",
    "chatGPT_response = []\n",
    "\n",
    "def addToList(response):\n",
    "    chatGPT_response.append(response.split())\n",
    "    print(response) \n",
    "\n",
    "\n",
    "print(\"Phrase 1:\")\n",
    "print(\"ChatGPT response:\")\n",
    "response_1 = run_gpt3(QUECHUA_TO_SPANISH_PROMPT.replace(\"{input}\", 'ñuqa aycha-ta-m miku-ni'), instruction_tuned=True)\n",
    "addToList(response_1)\n",
    "print(\"Actual Translation:\")\n",
    "print(\"yo como carne\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Phrase 2:\")\n",
    "print(\"ChatGPT response:\")\n",
    "response_2 = run_gpt3(QUECHUA_TO_SPANISH_PROMPT.replace(\"{input}\", 'Pitaq kanki?'), instruction_tuned=True)\n",
    "addToList(response_2)\n",
    "print(\"Actual Translation:\")\n",
    "print(\"¿quien eres?\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Phrase 3:\")\n",
    "print(\"ChatGPT response:\")\n",
    "response_3 = run_gpt3(QUECHUA_TO_SPANISH_PROMPT.replace(\"{input}\", 'Yachay wasinchikpi'), instruction_tuned=True)\n",
    "addToList(response_3)\n",
    "print(\"Actual Translation:\")\n",
    "print(\"En nuestra casa de estudios\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Phrase 4:\")\n",
    "print(\"ChatGPT response:\")\n",
    "response_4 = run_gpt3(QUECHUA_TO_SPANISH_PROMPT.replace(\"{input}\", 'Yachachiq yachachisqakunapas yachay wasi ukupi kachkanku.'), instruction_tuned=True)\n",
    "addToList(response_4)\n",
    "print(\"Actual Translation:\")\n",
    "print(\"El profesor y sus alumnos están en el aula.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Phrase 5:\")\n",
    "print(\"ChatGPT response:\")\n",
    "response_5 = run_gpt3(QUECHUA_TO_SPANISH_PROMPT.replace(\"{input}\", 'Allinllam, yachachiqniy, qamrí?'), instruction_tuned=True)\n",
    "addToList(response_5)\n",
    "print(\"Actual Translation:\")\n",
    "print(\"Estamos bien, mi profesor. ¿Y tú?\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Phrase 6:\")\n",
    "print(\"ChatGPT response:\")\n",
    "response_6 = run_gpt3(QUECHUA_TO_SPANISH_PROMPT.replace(\"{input}\", 'Ñuqataq San Isidropi tiyachkani.'), instruction_tuned=True)\n",
    "addToList(response_6)\n",
    "print(\"Actual Translation:\")\n",
    "print(\" Yo, por mi parte, vivo en San Isidro.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Phrase 7:\")\n",
    "print(\"ChatGPT response:\")\n",
    "response_7 = run_gpt3(QUECHUA_TO_SPANISH_PROMPT.replace(\"{input}\", 'Ñuqaqa mamaypaq yanuqmi kani, qamrí, yaw Ricardo?'), instruction_tuned=True)\n",
    "addToList(response_7)\n",
    "print(\"Actual Translation:\")\n",
    "print(\"Yo suelo cocinar para mi mamá, ¿y tú, oye, Ricardo?\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Phrase 8:\")\n",
    "print(\"ChatGPT response:\")\n",
    "response_8 = run_gpt3(QUECHUA_TO_SPANISH_PROMPT.replace(\"{input}\", 'Arí, ñuqaqa futbolpi pukllaqmi kani.'), instruction_tuned=True)\n",
    "addToList(response_8)\n",
    "print(\"Actual Translation:\")\n",
    "print(\"Sí, yo suelo jugar fútbol.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Phrase 9:\")\n",
    "print(\"ChatGPT response:\")\n",
    "response_9 = run_gpt3(QUECHUA_TO_SPANISH_PROMPT.replace(\"{input}\", 'Haykaptaq qawaytarí tukunki?'), instruction_tuned=True)\n",
    "addToList(response_9)\n",
    "print(\"Actual Translation:\")\n",
    "print(\"¿Cuándo vas a terminar la revista?\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Phrase 10:\")\n",
    "print(\"ChatGPT response:\")\n",
    "response_10 = run_gpt3(QUECHUA_TO_SPANISH_PROMPT.replace(\"{input}\", 'Imaynataq kachkan?'), instruction_tuned=True)\n",
    "addToList(response_10)\n",
    "print(\"Actual Translation:\")\n",
    "print(\"¿Cómo está?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d864dbe-2a7e-48fc-9d68-1aecff2bbeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Yo', 'estoy', 'comiendo', 'carne.'], ['¿Qué', 'piensas?.'], ['El', 'conocimiento', 'es', 'una', 'herramienta', 'poderosa', 'que', 'nos', 'permite', 'comprender', 'el', 'mundo', 'que', 'nos', 'rodea', 'y', 'tomar', 'decisiones', 'informadas.'], ['A', 'través', 'de', 'la', 'enseñanza', 'y', 'el', 'aprendizaje', 'en', 'la', 'escuela,', 'podemos', 'expandir', 'nuestro', 'conocimiento.'], ['¿Entiendes', 'todo', 'lo', 'que', 'te', 'he', 'enseñado?.'], ['Yo', 'creo', 'en', 'San', 'Isidro.'], ['¿Puedo', 'preguntarte', 'algo,', 'mamá,', 'por', 'favor,', 'Ricardo?.'], ['Sí,', 'yo', 'también', 'juego', 'al', 'fútbol.'], ['¿Qué', 'significa', 'eso', 'en', 'tu', 'idioma?.'], ['¿Qué', 'significa', 'eso?.']]\n"
     ]
    }
   ],
   "source": [
    "print(chatGPT_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d83ccc0-d8d2-41b5-88ec-7be7ca722454",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = [ \"yo como carne\".split(),\"¿quien eres?\".split(), \"En nuestra casa de estudios\".split(), \"El profesor y sus alumnos están en el aula.\".split(), \"Estamos bien, mi profesor. ¿Y tú?\".split(), \"Yo, por mi parte, vivo en San Isidro.\".split(), \"Yo suelo cocinar para mi mamá, ¿y tú, oye, Ricardo?\".split(), \"Sí, yo suelo jugar fútbol.\".split(), \"¿Cuándo vas a terminar la revista?\".split(), \"¿Cómo está?\".split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fcd434f-bb44-4feb-b974-f349f9010d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "9.257324954728539e-232\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Average BLEU score:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ihome/cs1671_2025s/rlb143/.local/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/ihome/cs1671_2025s/rlb143/.local/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/ihome/cs1671_2025s/rlb143/.local/lib/python3.11/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "avg = 0\n",
    "\n",
    "for value,response in zip(reference,chatGPT_response):\n",
    "    score = sentence_bleu(value, response)\n",
    "    avg = avg + score\n",
    "    print(score)\n",
    "\n",
    "print(\"Average BLEU score: \", score/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce160988-855a-45e9-b83c-86aca105339b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
